# -*- coding: utf-8 -*-
"""Hotel-Sales-Forecast-ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_MrBLAkwxzUWI3hvtfMLxQHolA5_tsCZ
"""

import pandas as pd
import numpy as np
from openpyxl import load_workbook
from datetime import datetime
import datetime as dt
import os

"""The code begins by importing necessary libraries and modules such as pandas, numpy, openpyxl, datetime, and os. It also mounts the Google Drive to access files from Google Colab."""

from google.colab import drive
drive.mount('/content/drive')

path = "/content/drive/My Drive/History and Forecast"

#Above line sets the path variable to the directory path where the Excel files are located.

columns = ["Actual Date", "Business Date", "Rooms Sold", "Rooms for Sale", "Arrival Rooms", "Compliment Rooms", "House Use", "Hold", "Individual Confirm", "Individual Tentative", "Group Confirm", "Group Tentative", "Occupancy %", "Room Revenue", "ARR", "Inclusion Revenue", "Departure Rooms", "OOO Rooms", "Pax", "Individual Revenue", "Individual ARR", "Confirmed Group Revenue", "Confirmed Group ARR", "Tentative Group Revenue", "Tentative Group ARR", "Total Room Inventory"]
df = pd.DataFrame(columns=columns)

#Here, a DataFrame named 'df' is created with the specified column names. This DataFrame will store the data extracted from Excel files.

for filename in os.listdir(path):
  if filename.endswith(".xlsx"):
    filepath = os.path.join(path, filename)
    wb = load_workbook(filename=filepath, read_only=True)
    ws = wb.active

    actual_date_str = ws.cell(row=8, column=1).value
    actual_date = actual_date_str.strftime("%Y-%m-%d")

    for row in ws.iter_rows(min_row=8, max_row=ws.max_row, min_col=1, max_col=26, values_only=True):
      if isinstance(row[0], (datetime, pd.Timestamp)):
        business_date = row[0].strftime("%Y-%m-%d")
        row_dict = {"Actual Date": actual_date, "Business Date": business_date}

        # Add the data from columns C to Z to the dictionary
        for i in range(2, 26):
          row_dict[columns[i]] = row[i]

        # Append the row data to the dataframe
        df = pd.concat([df, pd.DataFrame([row_dict])], ignore_index=True)

# Print the resulting dataframe
print(df)

"""The above block of code iterates through each file in the specified directory. It reads only the Excel files (with ".xlsx" extension). For each file, it loads the workbook, accesses the active sheet, and retrieves the actual date and business date from specific cells.

Then, it iterates through each row of the sheet, starting from row 8. It checks if the first column of the row contains a valid date. If it does, it creates a dictionary, 'row_dict', to store the data. The data from columns C to Z of the current row is added to 'row_dict'. Finally, the row data is appended to the 'df' DataFrame.
"""

#These lines convert the 'Actual Date' and 'Business Date' columns of the 'df' DataFrame to datetime format using the pd.to_datetime function. The modified DataFrame is then displayed.
df['Actual Date'] = pd.to_datetime(df['Actual Date'])
df['Business Date'] = pd.to_datetime(df['Business Date'])
df

# Filter the dataframe to keep only rows whose dates are on or before 5-5-2023
df = df[df['Business Date'] <= pd.Timestamp(2023, 5, 5)]
df

"""The above code filters the 'df' DataFrame to keep only the rows where the 'Business Date' is on or before May 5, 2023. The filtered DataFrame is assigned back to the 'df' variable."""

path = '/content/drive/MyDrive/weather_data_delhi.csv'
weather_data = pd.read_csv(path, usecols=['datetime', 'temp', 'humidity', 'precip'])
weather_data

"""In the above section, the code sets the path variable to the file location of the weather data CSV file. It then reads the CSV file using pd.read_csv and selects only the columns 'datetime', 'temp', 'humidity', and 'precip' using the usecols parameter. The resulting DataFrame is assigned to the 'weather_data' variable."""

weather_data['datetime'] = pd.to_datetime(weather_data['datetime'], format='%Y/%m/%d')
weather_data

"""Here, the 'datetime' column in the 'weather_data' DataFrame is converted to datetime format using the pd.to_datetime function. The format parameter specifies the date format in the original data."""

weather_data.rename(columns={'temp': 'Temperature', 'humidity': 'Humidity', 'precip': 'Precipitation'}, inplace=True)
# This line renames the columns in the 'weather_data' DataFrame. The column 'temp' is renamed to 'Temperature', 'humidity' is renamed to 'Humidity', and 'precip' is renamed to 'Precipitation'. The changes are made in-place using the inplace=True argument.

# merge the 'df' and 'weather_data' dataframes based on the 'Business Date' and 'date' columns
merged_df = pd.merge(df, weather_data, left_on='Business Date', right_on='datetime')

# drop the 'date' column from the merged dataframe
merged_df.drop('datetime', axis=1, inplace=True)

# print the updated dataframe
merged_df

"""In the above part, the code performs a merge operation between the 'df' DataFrame and the 'weather_data' DataFrame based on the 'Business Date' column in 'df' and the 'datetime' column in 'weather_data'. The merged DataFrame is assigned to the 'merged_df' variable.

After that, the 'datetime' column is dropped from the merged DataFrame using drop() with axis=1 (indicating the column axis) and inplace=True to modify the DataFrame in-place.

Finally, the updated merged DataFrame is printed.
"""

X = merged_df[['Actual Date', 'Business Date', 'Temperature', 'Humidity', 'Precipitation']]
y = merged_df['Rooms Sold']

X.head()

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb

# Preprocessing
X = merged_df[['Actual Date', 'Business Date', 'Temperature', 'Humidity', 'Precipitation']].copy()
y = merged_df['Rooms Sold'].copy()

# Convert datetime columns to datetime type
X['Actual Date'] = pd.to_datetime(X['Actual Date'])
X['Business Date'] = pd.to_datetime(X['Business Date'])

# Extract additional features from datetime columns
X['Actual Year'] = X['Actual Date'].dt.year
X['Actual Month'] = X['Actual Date'].dt.month
X['Actual Day'] = X['Actual Date'].dt.day

X['Business Year'] = X['Business Date'].dt.year
X['Business Month'] = X['Business Date'].dt.month
X['Business Day'] = X['Business Date'].dt.day

# Drop the original datetime columns
X.drop(['Actual Date', 'Business Date'], axis=1, inplace=True)

# Splitting data into train, validation, and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# XGBoost Model
model = xgb.XGBRegressor()

# Cross-validation
cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
cv_scores = -cv_scores  # Convert negative MSE scores to positive

# Train the model on the entire training set
model.fit(X_train, y_train)

# Predictions on the validation set
y_val_pred = model.predict(X_test)

# Predictions on the test set
y_test_pred = model.predict(X_test)

# Evaluation and Performance Metrics for Validation Set
mse_val = mean_squared_error(y_test, y_val_pred)
rmse_val = np.sqrt(mse_val)
r2_val = r2_score(y_test, y_val_pred)

# Evaluation and Performance Metrics for Test Set
mse_test = mean_squared_error(y_test, y_test_pred)
rmse_test = np.sqrt(mse_test)
r2_test = r2_score(y_test, y_test_pred)

print("Validation Set Metrics:")
print("Mean Squared Error (MSE):", mse_val)
print("Root Mean Squared Error (RMSE):", rmse_val)
print("R-squared (R2) Score:", r2_val)
print("")

print("Test Set Metrics:")
print("Mean Squared Error (MSE):", mse_test)
print("Root Mean Squared Error (RMSE):", rmse_test)
print("R-squared (R2) Score:", r2_test)
print("")

print("Cross-Validation Scores (Positive MSE):")
print(cv_scores)
print("Average Cross-Validation Score (Positive MSE):", np.mean(cv_scores))

import matplotlib.pyplot as plt

# Plotting the predicted values vs. the actual values for the validation set
plt.scatter(y_test, y_val_pred)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs. Predicted Values (Validation Set)')
plt.show()

# Plotting the residuals
residuals = y_test - y_val_pred
plt.scatter(y_test, residuals)
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Actual Values')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.show()

# Plotting the feature importances
feature_importances = model.feature_importances_
feature_names = X.columns
plt.barh(feature_names, feature_importances)
plt.xlabel('Importance')
plt.ylabel('Features')
plt.title('Feature Importances')
plt.show()

from sklearn.ensemble import RandomForestRegressor

# Preprocessing
X = merged_df[['Actual Date', 'Business Date', 'Temperature', 'Humidity', 'Precipitation']].copy()
y = merged_df['Rooms Sold']

# Convert datetime columns to datetime type
X['Actual Date'] = pd.to_datetime(X['Actual Date'])
X['Business Date'] = pd.to_datetime(X['Business Date'])

# Extract additional features from datetime columns
X['Actual Year'] = X['Actual Date'].dt.year
X['Actual Month'] = X['Actual Date'].dt.month
X['Actual Day'] = X['Actual Date'].dt.day

X['Business Year'] = X['Business Date'].dt.year
X['Business Month'] = X['Business Date'].dt.month
X['Business Day'] = X['Business Date'].dt.day

# Drop the original datetime columns
X = X.drop(['Actual Date', 'Business Date'], axis=1)

# Splitting data into train, validation, and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest Regressor Model
model = RandomForestRegressor()

# Cross-validation
cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
cv_scores = -cv_scores  # Convert negative MSE scores to positive

# Train the model on the entire training set
model.fit(X_train, y_train)

# Predictions on the validation set
y_val_pred = model.predict(X_test)

# Predictions on the test set
y_test_pred = model.predict(X_test)

# Evaluation and Performance Metrics for Validation Set
mse_val = mean_squared_error(y_test, y_val_pred)
rmse_val = np.sqrt(mse_val)
r2_val = r2_score(y_test, y_val_pred)

# Evaluation and Performance Metrics for Test Set
mse_test = mean_squared_error(y_test, y_test_pred)
rmse_test = np.sqrt(mse_test)
r2_test = r2_score(y_test, y_test_pred)

print("Validation Set Metrics:")
print("Mean Squared Error (MSE):", mse_val)
print("Root Mean Squared Error (RMSE):", rmse_val)
print("R-squared (R2) Score:", r2_val)
print("")

print("Test Set Metrics:")
print("Mean Squared Error (MSE):", mse_test)
print("Root Mean Squared Error (RMSE):", rmse_test)
print("R-squared (R2) Score:", r2_test)
print("")

print("Cross-Validation Scores (Positive MSE):")
print(cv_scores)
print("Average Cross-Validation Score (Positive MSE):", np.mean(cv_scores))

# Plotting Performance Metrics
labels = ['MSE', 'RMSE', 'R2 Score']
validation_scores = [mse_val, rmse_val, r2_val]
test_scores = [mse_test, rmse_test, r2_test]

x = np.arange(len(labels))
width = 0.35

fig, ax = plt.subplots()
rects1 = ax.bar(x - width/2, validation_scores, width, label='Validation Set')
rects2 = ax.bar(x + width/2, test_scores, width, label='Test Set')

ax.set_ylabel('Score')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

fig.tight_layout()

# Plotting Feature Importance
feature_importance = model.feature_importances_
sorted_feature_indices = np.argsort(feature_importance)[::-1]
sorted_feature_names = X.columns[sorted_feature_indices]
sorted_feature_importance = feature_importance[sorted_feature_indices]

plt.figure(figsize=(8, 6))
plt.barh(range(len(sorted_feature_names)), sorted_feature_importance, align='center')
plt.yticks(range(len(sorted_feature_names)), sorted_feature_names)
plt.xlabel('Feature Importance')
plt.ylabel('Features')
plt.title('Random Forest Regressor - Feature Importance')

plt.show()